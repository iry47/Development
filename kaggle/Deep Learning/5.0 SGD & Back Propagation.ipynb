{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent (SGD)\n",
    "\n",
    "An algorithm that uses the loss function of the model to determine the local minimum. The local minimum of the loss functions is the location that produces the smallest error for our predictive results.\n",
    "\n",
    "With SGD, instead of taking each individual data point at a time, we take groups of data or batches. The size of these bathches, or gradient, determines the size of the step that we take walking down to the local minimum of the loss function. In other words, small batches require more computational power.\n",
    "\n",
    "\n",
    "# Backpropagation \n",
    "\n",
    "An algorithm that computes the gradient of the loss function with respect to the weights of the network for a single input-output example, and does so efficiently.\n",
    "\n",
    "This algorithm works by computing the gradient of the loss function with respect to each weight by the chain rule, computing the gradient one layer at a time, iterating backward from the last layer to avoid redundant calculations of internmediate terms in the chain rule."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "In this example, a csv file of pixel information is used to determine the contents of the images. The first column in the file contains the label, and every following column in the same row contains the pixel intensity for the specified pixel of the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "\n",
    "img_row, img_cols = 28, 28\n",
    "num_classes = 10\n",
    "\n",
    "def prep_data(raw):\n",
    "    y = raw[:, 0]\n",
    "    out_y = keras.utils.to_categorical(y, num_classes)\n",
    "    \n",
    "    x = raw[:, 1:]\n",
    "    num_images = raw.shape[0]\n",
    "    out_x = x.reshape(num_images, img_rows, img_cols, 1)\n",
    "    out_x = out_x / 255\n",
    "    return out_x, out_y\n",
    "\n",
    "# fashion_file = '' #must make file\n",
    "# fashion_data = np.loadtxt(fashion_file, skiprows=1, delimiter=',')\n",
    "# x, y = prep_data(fashion_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
    "\n",
    "fashion_model = Sequential()\n",
    "fashion_model.add(Conv2D(kernel_size=3,filters=12,activation='relu',input_shape=(img_rows,img_cols,1)))\n",
    "fashion_model.add(Conv2D(20, activation='relu', kernel_size=3))\n",
    "fashion_model.add(Conv2D(20, activation='relu', kernel_size=3))\n",
    "fashion_model.add(Flatten())\n",
    "fashion_model.add(Dense(100, activation='relu'))\n",
    "fashion_model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "fashion_model.compile(optimizer='adam',\n",
    "                     loss='categorical_crossentropy',\n",
    "                     metrics=['accuracy'])\n",
    "\n",
    "fashion_model.fit(x, y,\n",
    "                 batch_size=100,\n",
    "                 epochs=4,\n",
    "                 validation_split=0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
